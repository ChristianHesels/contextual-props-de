{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 3.50MB/s]                    \n",
      "2020-05-11 13:25:59 INFO: Downloading default packages for language: de (German)...\n",
      "2020-05-11 13:26:00 INFO: File exists: /home/chris/stanza_resources/de/default.zip.\n",
      "2020-05-11 13:26:04 INFO: Finished downloading models and saved to /home/chris/stanza_resources.\n",
      "2020-05-11 13:26:04 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "| ner       | conll03 |\n",
      "=======================\n",
      "\n",
      "2020-05-11 13:26:04 INFO: Use device: gpu\n",
      "2020-05-11 13:26:04 INFO: Loading: tokenize\n",
      "2020-05-11 13:26:04 INFO: Loading: mwt\n",
      "2020-05-11 13:26:04 INFO: Loading: pos\n",
      "2020-05-11 13:26:05 INFO: Loading: lemma\n",
      "2020-05-11 13:26:05 INFO: Loading: depparse\n",
      "2020-05-11 13:26:05 INFO: Loading: ner\n",
      "2020-05-11 13:26:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import os, sys, codecs, time, datetime\n",
    "import fileinput\n",
    "import os.path\n",
    "from io import StringIO\n",
    "from subprocess import call\n",
    "\n",
    "\n",
    "from docopt import docopt\n",
    "from propsde.applications.viz_tree import DepTreeVisualizer\n",
    "\n",
    "import propsde.applications.run as run\n",
    "import sys\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n",
    "    \n",
    "stanza.download('de')\n",
    "nlp = stanza.Pipeline('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('polizeiberichte.pkl', 'rb') as f:\n",
    "    data = pickle.load(f, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Polizeiliche Staatsschutz beim Landeskriminalamt ermittelt wegen gemeinschädlicher Sachbeschädigung an einem jüdischen Mahnmal in Tiergarten. Passanten hatten heute früh gegen 8.50 Uhr gelbe Schmierereien an der Gedenktafel in der Levetzowstraße entdeckt und die Polizei alarmiert.\n"
     ]
    }
   ],
   "source": [
    "text_example = data[72][\"text1\"]\n",
    "print(text_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_example = text_example.replace(\". \", \".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Polizeiliche Staatsschutz beim Landeskriminalamt ermittelt wegen gemeinschädlicher Sachbeschädigung an einem jüdischen Mahnmal in Tiergarten.\n",
      "Passanten hatten heute früh gegen 8.50 Uhr gelbe Schmierereien an der Gedenktafel in der Levetzowstraße entdeckt und die Polizei alarmiert.\n"
     ]
    }
   ],
   "source": [
    "print(text_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running mate-tools\n",
      "lemmatizing\n",
      "parsing + tagging\n",
      "collapsing\n",
      "java -jar ext/org.jobimtext.collapsing.jar -i tmp/parsed.conll06 -o tmp -sf -l de -r ext/resources/german_modified.txt -f c -np -nt\n"
     ]
    }
   ],
   "source": [
    "file = codecs.open(\"examples.txt\", encoding='utf8')\n",
    "gs = run.parseSentences(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fahren:(subj:Der regierende Bürgermeister , prep_zu:Rathaus )\n",
      "gehen:(subj:er , prep_in:roten Rathaus , prep_in:den Sitzungssaal )\n",
      "liegen:(subj:Der alte Sitzungssaal , prep_neben:dem Büro von Michael Müller )\n"
     ]
    }
   ],
   "source": [
    "for g,tree in gs: \n",
    "    for prop in g.getPropositions('pdf'):\n",
    "        curProp = '{0}:({1})'.format(prop.pred,\n",
    "                                      \", \".join([rel + \":\" + arg for rel,arg in sorted(prop.args,key=lambda rel:prop.rel_order(rel[0]))]))\n",
    "        print(curProp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['subj', 'Der alte Sitzungssaal '], ['prep_neben', 'dem Büro von Michael Müller ']]\n",
      "liegen\n"
     ]
    }
   ],
   "source": [
    "prop = g.getPropositions('pdf')[0]\n",
    "print(prop.args)\n",
    "print(prop.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der regierende Bürgermeister fährt zum Rathaus .\n",
      "20\t2,regierende\tADJA\t0\t0\tmod,21\n",
      "21\t3,Bürgermeister\tNN\t0\t0\tsubj,22\n",
      "22\t4,fährt\tVVFIN\t1\t1\t\n",
      "23\t6,Rathaus\tNN\t0\t0\tprep_zu,22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = gs[0][0]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "import stanza\n",
    "\n",
    "def _map_article_of_subj_to_pronoun(arg):\n",
    "    personal_pronouns = {\"der\": \"er\", \"das\": \"es\", \"die\": \"sie\", \"dem\": \"er\", \"den\": \"sie\"}\n",
    "    \n",
    "    if \"subj\" in arg:\n",
    "        words = arg[1].lower().split()\n",
    "        pronoun_place = list(word in personal_pronouns for word in words)\n",
    "        pronoun = list(compress(words, pronoun_place))\n",
    "        if len(pronoun) == 1:\n",
    "            current_subj = (personal_pronouns[pronoun[0]], arg[1])\n",
    "            return current_subj\n",
    "    return None\n",
    "\n",
    "def _get_core_from_noun_phrase(noun_phrase):\n",
    "    pos_tag = nlp(noun_phrase)\n",
    "    for sent in pos_tag.sentences:\n",
    "        for word in sent.words:\n",
    "            if word.xpos == \"NN\" or word.xpos == \"NE\":\n",
    "                return word.lemma\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "nouns = []\n",
    "prop_cache = []\n",
    "index = 0\n",
    "\n",
    "for i, (g, tree) in enumerate(gs):\n",
    "    subjects.append([])\n",
    "    for prop in g.getPropositions('pdf'):\n",
    "        prop_cache.append({\"args\": prop.args, \"pred\": prop.pred})\n",
    "        \n",
    "while index < len(prop_cache):\n",
    "    for i, arg in enumerate(prop_cache[index][\"args\"]):\n",
    "        words = arg[1].lower().split()\n",
    "        _article_pronoun = _map_article_of_subj_to_pronoun(arg)\n",
    "        _noun_phrase_core = _get_core_from_noun_phrase(arg[1])\n",
    "        if _article_pronoun:\n",
    "            subjects[i].append(_article_pronoun)\n",
    "        if _noun_phrase_core:\n",
    "            nouns.append(_noun_phrase_core)\n",
    "            nouns = list(set(nouns))\n",
    "        \n",
    "        if _noun_phrase_core in nouns:\n",
    "            #prop_cache[index][\"args\"][i][1] = {\"core\": _noun_phrase_core, \"np\": arg[1]}\n",
    "            prop_cache[index][\"args\"][i][1] = _noun_phrase_core\n",
    "        if i > 0 and len(subjects[i-1]) > 0 and subjects[i-1][0][0] in words:\n",
    "            prop_cache[index][\"args\"][i][1] = _get_core_from_noun_phrase(subjects[i-1][0][1])\n",
    "    \n",
    "\n",
    "    index += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der regierende Bürgermeister fährt zum Rathaus.\n",
    "Im roten Rathaus geht er in den Sitzungssaal.\n",
    "Der alte Sitzungssaal liegt neben dem Büro von Michael Müller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': [['subj', 'Bürgermeister'], ['prep_zu', 'Rathaus']], 'pred': 'fahren'}\n",
      "{'args': [['prep_in', 'Rathaus'], ['subj', 'Bürgermeister'], ['prep_in', 'Sitzungssaal']], 'pred': 'gehen'}\n",
      "{'args': [['subj', 'Sitzungssaal'], ['prep_neben', 'Büro']], 'pred': 'liegen'}\n"
     ]
    }
   ],
   "source": [
    "for prop in prop_cache:\n",
    "    print(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
