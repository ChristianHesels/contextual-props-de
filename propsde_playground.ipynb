{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 3.90MB/s]                    \n",
      "2020-05-12 09:56:42 INFO: Downloading default packages for language: de (German)...\n",
      "2020-05-12 09:56:43 INFO: File exists: /home/chris/stanza_resources/de/default.zip.\n",
      "2020-05-12 09:56:48 INFO: Finished downloading models and saved to /home/chris/stanza_resources.\n",
      "2020-05-12 09:56:48 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "| ner       | conll03 |\n",
      "=======================\n",
      "\n",
      "2020-05-12 09:56:48 INFO: Use device: gpu\n",
      "2020-05-12 09:56:48 INFO: Loading: tokenize\n",
      "2020-05-12 09:56:51 INFO: Loading: mwt\n",
      "2020-05-12 09:56:51 INFO: Loading: pos\n",
      "2020-05-12 09:56:52 INFO: Loading: lemma\n",
      "2020-05-12 09:56:52 INFO: Loading: depparse\n",
      "2020-05-12 09:56:53 INFO: Loading: ner\n",
      "2020-05-12 09:56:53 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import os, sys, codecs, time, datetime\n",
    "import fileinput\n",
    "import os.path\n",
    "import stanza\n",
    "from io import StringIO\n",
    "from subprocess import call\n",
    "\n",
    "\n",
    "from docopt import docopt\n",
    "from propsde.applications.viz_tree import DepTreeVisualizer\n",
    "\n",
    "import propsde.applications.run as run\n",
    "import sys\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n",
    "    \n",
    "stanza.download('de')\n",
    "nlp = stanza.Pipeline('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('polizeiberichte.pkl', 'rb') as f:\n",
    "    data = pickle.load(f, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gute Texte: 5\n",
    "Schwierige Texte: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Täter versuchten in der Nacht vom 19. zum 20. Juni 2014, die Eingangstür des Bürokomplexes in der Feldtmannstraße gewaltsam zu öffnen. Als dies nicht gelang, hebelten sie schließlich ein Fenster an der Rückseite des Hauses auf und gelangten so in das Objekt. Aus den Büroräumen mehrerer dort ansässiger Firmen entwendeten sie neben Geld auch eine EC-Karte, die bereits am Freitag, 20. Juni 2014, gegen 5.10 Uhr an einem Geldautomaten in der Danziger Straße eingesetzt wurde.\n"
     ]
    }
   ],
   "source": [
    "text_example = data[22][\"text1\"]\n",
    "print(text_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_example = text_example.replace(\". \", \".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Täter versuchten in der Nacht vom 19.\n",
      "zum 20.\n",
      "Juni 2014, die Eingangstür des Bürokomplexes in der Feldtmannstraße gewaltsam zu öffnen.\n",
      "Als dies nicht gelang, hebelten sie schließlich ein Fenster an der Rückseite des Hauses auf und gelangten so in das Objekt.\n",
      "Aus den Büroräumen mehrerer dort ansässiger Firmen entwendeten sie neben Geld auch eine EC-Karte, die bereits am Freitag, 20.\n",
      "Juni 2014, gegen 5.10 Uhr an einem Geldautomaten in der Danziger Straße eingesetzt wurde.\n"
     ]
    }
   ],
   "source": [
    "print(text_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running mate-tools\n",
      "lemmatizing\n",
      "parsing + tagging\n",
      "collapsing\n",
      "java -jar ext/org.jobimtext.collapsing.jar -i tmp/parsed.conll06 -o tmp -sf -l de -r ext/resources/german_modified.txt -f c -np -nt\n",
      "UFF\n"
     ]
    }
   ],
   "source": [
    "file = codecs.open(\"examples.txt\", encoding='utf8')\n",
    "gs = run.parseSentences(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versuchen:(subj:Die Täter , prep_in:der Nacht vom 19 )\n",
      "Juni 2014:(dobj:die Eingangstür des Bürokomplexes in der Feldtmannstraße gewaltsam zu öffnen )\n",
      "gelangt:(subj:sie , prep_in:das Objekt , mod:so )\n",
      "aufhebeln:(subj:sie , dobj:ein Fenster an der Rückseite des Hauses , mod:Als dies nicht gelang , mod:schließlich )\n",
      "und:(conj_und:Als dies nicht gelang , hebelten sie schließlich ein Fenster an der Rückseite des Hauses auf , conj_und:sie gelangten so in das Objekt )\n",
      "entwenden:(subj:sie , dobj:auch eine EC-Karte , die bereits an Freitag , 20 , prep_aus:den Büroräumen mehrerer dort ansässiger Firmen , prep_neben:Geld )\n",
      "20:(subj:auch eine EC-Karte , prep_an:Freitag , mod:bereits )\n",
      "einsetzen:(obj:Juni 2014 , prep_gegen:5.10 Uhr , prep_an:einem Geldautomaten in der Danziger Straße )\n"
     ]
    }
   ],
   "source": [
    "for g,tree in gs: \n",
    "    for prop in g.getPropositions('pdf'):\n",
    "        curProp = '{0}:({1})'.format(prop.pred,\n",
    "                                      \", \".join([rel + \":\" + arg for rel,arg in sorted(prop.args,key=lambda rel:prop.rel_order(rel[0]))]))\n",
    "        print(curProp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['obj', 'Juni 2014 '], ['prep_gegen', '5.10 Uhr '], ['prep_an', 'einem Geldautomaten in der Danziger Straße ']]\n",
      "einsetzen\n"
     ]
    }
   ],
   "source": [
    "prop = g.getPropositions('pdf')[0]\n",
    "print(prop.args)\n",
    "print(prop.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Täter versuchten in der Nacht vom 19 .\n",
      "519\t2,Täter\tNN\t0\t0\tsubj,520\n",
      "520\t3,versuchten\tVVFIN\t1\t1\t\n",
      "522\t6,Nacht\tNN\t0\t0\tprep_in,520\n",
      "602\t7,vom;8,19\t\t0\t0\tmod,522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = gs[0][0]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "\n",
    "def _map_article_of_subj_to_pronoun(arg):\n",
    "    personal_pronouns = {\"der\": \"er\", \"das\": \"es\", \"die\": \"sie\", \"dem\": \"er\", \"den\": \"sie\"}\n",
    "    \n",
    "    if \"subj\" in arg:\n",
    "        words = arg[1].lower().split()\n",
    "        pronoun_place = list(word in personal_pronouns for word in words)\n",
    "        pronoun = list(compress(words, pronoun_place))\n",
    "    \n",
    "        if len(pronoun) == 1:\n",
    "            current_subj = (personal_pronouns[pronoun[0]], arg[1])\n",
    "            return current_subj\n",
    "    return None\n",
    "\n",
    "def _get_core_from_noun_phrase(noun_phrase):\n",
    "    pos_tag = nlp(noun_phrase)\n",
    "    for sent in pos_tag.sentences:\n",
    "        for word in sent.words:\n",
    "            if word.head == 0:\n",
    "                return {\"np\": noun_phrase, \"core:\":word.lemma}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "subjects = []\n",
    "nouns = []\n",
    "prop_cache = []\n",
    "index = 0\n",
    "\n",
    "for i, (g, tree) in enumerate(gs):\n",
    "    for prop in g.getPropositions('pdf'):\n",
    "        subjects.append([])\n",
    "        prop_cache.append({\"args\": prop.args, \"pred\": prop.pred})\n",
    "        \n",
    "while index < len(prop_cache):\n",
    "    for i, arg in enumerate(prop_cache[index][\"args\"]):\n",
    "        words = arg[1].lower().split()\n",
    "\n",
    "        _article_pronoun = _map_article_of_subj_to_pronoun(arg)\n",
    "        _noun_phrase_core = _get_core_from_noun_phrase(arg[1])\n",
    "        if _article_pronoun:\n",
    "            subjects[i].append(_article_pronoun)\n",
    "        if _noun_phrase_core:\n",
    "            nouns.append(_noun_phrase_core)\n",
    "        if _noun_phrase_core in nouns:\n",
    "            #prop_cache[index][\"args\"][i][1] = {\"core\": _noun_phrase_core, \"np\": arg[1]}\n",
    "            prop_cache[index][\"args\"][i][1] = _noun_phrase_core\n",
    "        for j in range(1, len(subjects)):\n",
    "            try:\n",
    "                if index > 0 and len(subjects[index-j]) > 0 and subjects[index-j][0][0] in words:\n",
    "                    prop_cache[index][\"args\"][i][1] = _get_core_from_noun_phrase(subjects[index-j][0][1])\n",
    "                    pass\n",
    "            except:\n",
    "                print(\"Error\")\n",
    "    index += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der regierende Bürgermeister fährt zum Rathaus.\n",
    "Im roten Rathaus geht er in den Sitzungssaal.\n",
    "Der alte Sitzungssaal liegt neben dem Büro von Michael Müller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': [['subj', {'np': 'Die Täter ', 'core:': 'Täter'}], ['prep_in', {'np': 'der Nacht vom 19 ', 'core:': 'Nacht'}]], 'pred': 'versuchen'}\n",
      "{'args': [['dobj', {'np': 'die Eingangstür des Bürokomplexes in der Feldtmannstraße gewaltsam zu öffnen ', 'core:': 'öffnen'}]], 'pred': 'Juni 2014'}\n",
      "{'args': [['subj', {'np': 'Die Täter ', 'core:': 'Täter'}], ['mod', {'np': 'so ', 'core:': 'so'}], ['prep_in', {'np': 'das Objekt ', 'core:': 'Objekt'}]], 'pred': 'gelangt'}\n",
      "{'args': [['mod', {'np': 'Als dies nicht gelang ', 'core:': 'gelingen'}], ['subj', {'np': 'Die Täter ', 'core:': 'Täter'}], ['mod', {'np': 'schließlich ', 'core:': 'schließlich'}], ['dobj', {'np': 'ein Fenster an der Rückseite des Hauses ', 'core:': 'Fenster'}]], 'pred': 'aufhebeln'}\n",
      "{'args': [['conj_und', {'np': 'Die Täter ', 'core:': 'Täter'}], ['conj_und', {'np': 'Die Täter ', 'core:': 'Täter'}]], 'pred': 'und'}\n",
      "{'args': [['prep_aus', {'np': 'den Büroräumen mehrerer dort ansässiger Firmen ', 'core:': 'Büroraum'}], ['subj', {'np': 'Die Täter ', 'core:': 'Täter'}], ['prep_neben', {'np': 'Geld ', 'core:': 'Geld'}], ['dobj', {'np': 'auch eine EC-Karte , die bereits an Freitag , 20 ', 'core:': 'EC'}]], 'pred': 'entwenden'}\n",
      "{'args': [['subj', {'np': 'auch eine EC-Karte ', 'core:': 'EC'}], ['mod', {'np': 'bereits ', 'core:': 'bereits'}], ['prep_an', {'np': 'Freitag ', 'core:': 'Freitag'}]], 'pred': '20'}\n",
      "{'args': [['obj', {'np': 'Juni 2014 ', 'core:': 'Juni'}], ['prep_gegen', {'np': '5.10 Uhr ', 'core:': 'Uhr'}], ['prep_an', {'np': 'einem Geldautomaten in der Danziger Straße ', 'core:': 'Geldautomaten'}]], 'pred': 'einsetzen'}\n"
     ]
    }
   ],
   "source": [
    "for prop in prop_cache:\n",
    "    print(prop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": \"1\",\n",
       "      \"text\": \"mehrere\",\n",
       "      \"lemma\": \"mehrere\",\n",
       "      \"upos\": \"PRON\",\n",
       "      \"xpos\": \"PIS\",\n",
       "      \"feats\": \"Case=Nom|Definite=Ind|Number=Plur|PronType=Ind\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"misc\": \"start_char=0|end_char=7\"\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"mehrere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for j in range(5, 0, -1):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
